# üé¨ Transcribe and Translate Subtitles

<div align="center">

**A powerful, privacy-first tool for transcribing and translating video subtitles**

[![Privacy First](https://img.shields.io/badge/Privacy-100%25%20Local-green.svg)](https://github.com/your-repo)
[![ONNX Runtime](https://img.shields.io/badge/Powered%20by-ONNX%20Runtime-blue.svg)](https://onnxruntime.ai/)
[![Multi-Platform](https://img.shields.io/badge/Platform-Windows%20%7C%20Linux%20%7C%20macOS-lightgrey.svg)](https://github.com/your-repo)

</div>

---

## üîí Privacy Guarantee

> **üö® All processing runs completely offline** - No internet connection required, ensuring maximum privacy and data security.

---

## üìã Complete Update History

### üÜï **2025/9/19** - Major Release
- ‚úÖ **Added ASR**: 30+ region fine-tuned Whisper models
- ‚úÖ **Added Denoiser**: MossFormer2_SE_48K
- ‚úÖ **Added LLM Models**:
  - Qwen3-4B-Instruct-2507-abliterated
  - Qwen3-8B-abliterated-v2
  - Hunyuan-MT-7B-abliterated
  - Seed-X-PRO-7B
- ‚úÖ **Performance Improvements**:
  - Applied Beam Search for Whisper-like ASR models
  - Applied ONNX Runtime IOBinding for maximum speed up (10%+ faster than normal ort_session_C.run())
  - Support for 20 seconds audio segment per single run inference
  - Improved multi-threads performance
- ‚úÖ **Hardware Support Expansion**:
  - AMD-ROCm Execution Provider
  - AMD-MIGraphX Execution Provider
  - NVIDIA TensorRTX Execution Provider
  - *(Must config the env first or it will not work)*
- ‚úÖ **Accuracy Improvements**:
  - SenseVoice
  - Paraformer
  - FireRedASR
  - Dolphin
  - ZipEnhancer
  - MossFormerGAN_SE_16K
  - NVIDIA-NeMo-VAD
- ‚úÖ **Speed Improvements**:
  - MelBandRoformer (speed boost by converting to mono channel)
- ‚ùå **Removed Models**:
  - FSMN-VAD
  - Qwen3-4B-Official
  - Qwen3-8B-Official
  - Gemma3-4B-it
  - Gemma3-12B-it
  - InternLM3
  - Phi-4-Instruct

### **2025/7/5** - Noise Reduction Enhancement
- ‚úÖ **Added noise reduction model**: MossFormerGAN_SE_16K

### **2025/6/11** - VAD Models Expansion
- ‚úÖ **Added VAD Models**:
  - HumAware-VAD
  - NVIDIA-NeMo-VAD
  - TEN-VAD

### **2025/6/3** - Asian Language Support
- ‚úÖ **Added Dolphin ASR model** to support Asian languages

### **2025/5/13** - GPU Acceleration
- ‚úÖ **Added Float16/32 ASR models** to support CUDA/DirectML GPU usage
- ‚úÖ **GPU Performance**: These models can achieve >99% GPU operator deployment

### **2025/5/9** - Major Feature Release
- ‚úÖ **Flexibility Improvements**:
  - Added option to **not use** VAD (Voice Activity Detection)
- ‚úÖ **Added Models**:
  - **Noise reduction**: MelBandRoformer
  - **ASR**: CrisperWhisper
  - **ASR**: Whisper-Large-v3.5-Distil (English fine-tuned)
  - **ASR**: FireRedASR-AED-L (Chinese + dialects support)
  - **Three Japanese anime fine-tuned Whisper models**
- ‚úÖ **Performance Optimizations**:
  - Removed IPEX-LLM framework to enhance overall performance
  - Cancelled LLM quantization options, standardized on **Q4F32** format
  - Improved **Whisper** series inference speed by over 10%
- ‚úÖ **Accuracy Improvements**:
  - Improved **FSMN-VAD** accuracy
  - Improved **Paraformer** recognition accuracy
  - Improved **SenseVoice** recognition accuracy
- ‚úÖ **LLM Support with ONNX Runtime 100% GPU operator deployment**:
  - Qwen3-4B/8B
  - InternLM3-8B
  - Phi-4-mini-Instruct
  - Gemma3-4B/12B-it
- ‚úÖ **Hardware Support Expansion**:
  - **Intel OpenVINO**
  - **NVIDIA CUDA GPU**
  - **Windows DirectML GPU** (supports integrated and discrete GPUs)

---

## üöÄ Quick Start

### Prerequisites
```bash
# Install FFmpeg
conda install ffmpeg

# Install Python dependencies
pip install -r requirements.txt
```

### Setup
1. **Download Models**: Get the required models from [HuggingFace](https://huggingface.co/H5N1AIDS/Transcribe_and_Translate_Subtitles)
2. **Download Script**: Place `run.py` in your `Transcribe_and_Translate_Subtitles` folder
3. **Add Media**: Place your videos in `Transcribe_and_Translate_Subtitles/Media/`
4. **Run**: Execute `python run.py` and open the web interface

### Results
Find your processed subtitles in:
```
Transcribe_and_Translate_Subtitles/Results/Subtitles/
```

---

## ‚ú® Features

### üîá Noise Reduction Models
- **[DFSMN](https://modelscope.cn/models/iic/speech_dfsmn_ans_psm_48k_causal)** - High-quality denoising
- **[GTCRN](https://github.com/Xiaobin-Rong/gtcrn)** - Real-time noise suppression
- **[ZipEnhancer](https://modelscope.cn/models/iic/speech_zipenhancer_ans_multiloss_16k_base)** - Advanced enhancement
- **[Mel-Band-Roformer](https://github.com/KimberleyJensen/Mel-Band-Roformer-Vocal-Model)** - Vocal isolation
- **[MossFormerGAN_SE_16K](https://www.modelscope.cn/models/alibabasglab/MossFormerGAN_SE_16K)** - 16kHz enhancement
- **[MossFormer2_SE_48K](https://www.modelscope.cn/models/alibabasglab/MossFormer2_SE_48K)** - 48kHz enhancement

### üé§ Voice Activity Detection (VAD)
- **[Faster_Whisper-Silero](https://github.com/SYSTRAN/faster-whisper/blob/master/faster_whisper/vad.py)** - Fast and accurate
- **[Official-Silero-v6](https://github.com/snakers4/silero-vad)** - Official implementation
- **[HumAware](https://huggingface.co/CuriousMonkey7/HumAware-VAD)** - Human-aware detection
- **[NVIDIA-NeMo-VAD-v2.0](https://huggingface.co/nvidia/Frame_VAD_Multilingual_MarbleNet_v2.0)** - Multilingual support
- **[TEN-VAD](https://github.com/TEN-framework/ten-vad)** - Lightweight detection
- **[Pyannote-Segmentation-3.0](https://huggingface.co/pyannote/segmentation-3.0)** - Advanced segmentation
  - *Note: You need to accept Pyannote's terms of use and download the Pyannote `pytorch_model.bin` file. Place it in the `VAD/pyannote_segmentation` folder.*

### üó£Ô∏è Speech Recognition (ASR)
#### Multilingual Models
- **[SenseVoice-Small](https://modelscope.cn/models/iic/SenseVoiceSmall)** - Compact multilingual
- **[Whisper-Large-V3](https://huggingface.co/openai/whisper-large-v3)** - State-of-the-art accuracy
- **[Whisper-Large-V3-Turbo](https://huggingface.co/openai/whisper-large-v3-turbo)** - Speed optimized
- **[CrisperWhisper](https://github.com/nyrahealth/CrisperWhisper)** - Enhanced clarity
- **[Dolphin-Small](https://github.com/DataoceanAI/Dolphin)** - Asian language support

#### Chinese Models
- **[Paraformer-Small-Chinese](https://modelscope.cn/models/iic/speech_paraformer_asr_nat-zh-cn-16k-common-vocab8358-tensorflow1)** - Compact Chinese
- **[Paraformer-Large-Chinese](https://modelscope.cn/models/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch)** - Advanced Chinese
- **[FireRedASR-AED-L](https://github.com/FireRedTeam/FireRedASR)** - Chinese dialects support

#### English Models
- **[Paraformer-Large-English](https://modelscope.cn/models/iic/speech_paraformer_asr-en-16k-vocab4199-pytorch)** - English specialized
- **[Whisper-Large-v3.5-Distil](https://huggingface.co/distil-whisper/distil-large-v3.5)** - Distilled efficiency

#### Japanese Models
- **[Whisper-Large-V3-Turbo-Japanese](https://huggingface.co/hhim8826/whisper-large-v3-turbo-ja)** - Japanese optimized
- **[Whisper-Large-V3-Anime-A](https://huggingface.co/efwkjn/whisper-ja-anime-v0.1)** - Anime specialized
- **[Whisper-Large-V3-Anime-B](https://huggingface.co/litagin/anime-whisper)** - Alternative anime model

### ü§ñ Translation Models (LLM)
- **[Qwen-3-4B-Instruct-2507](https://huggingface.co/huihui-ai/Huihui-Qwen3-4B-Instruct-2507-abliterated)** - Efficient instruction following
- **[Qwen-3-8B-Fine_Tuned](https://huggingface.co/huihui-ai/Huihui-Qwen3-8B-abliterated-v2)** - Enhanced 8B variant
- **[Hunyuan-MT-7B](https://www.modelscope.cn/models/Tencent-Hunyuan/Hunyuan-MT-7B)** - Machine translation specialist
- **[Seed-X-PRO-7B](https://www.modelscope.cn/models/ByteDance-Seed/Seed-X-PPO-7B)** - Advanced reasoning

---

## üñ•Ô∏è Hardware Support

<table>
<tr>
<td align="center"><strong>üíª CPU</strong></td>
<td align="center"><strong>üéÆ GPU</strong></td>
<td align="center"><strong>üß† Specialized</strong></td>
</tr>
<tr>
<td>Intel ‚Ä¢ AMD ‚Ä¢ Apple Silicon</td>
<td>NVIDIA CUDA ‚Ä¢ AMD ROCm ‚Ä¢ DirectML</td>
<td>Intel OpenVINO ‚Ä¢ TensorRT ‚Ä¢ MIGraphX</td>
</tr>
</table>

**Currently Supported Platforms:**
- **Intel-OpenVINO-CPU-GPU-NPU**
- **Windows-AMD-GPU**
- **NVIDIA-GPU**
- **Apple-CPU**
- **AMD-CPU**

---

## üìä Performance Benchmarks

*Test conditions: Ubuntu 24.04, Intel i3-12300, 7602-second video*

| OS | Backend | Denoiser | VAD | ASR | LLM | Real-Time Factor |
|:--:|:-------:|:--------:|:---:|:---:|:---:|:----------------:|
| Ubuntu-24.04 | CPU i3-12300 | - | Silero | SenseVoiceSmall | - | **0.08** |
| Ubuntu-24.04 | CPU i3-12300 | GTCRN | Silero | SenseVoiceSmall | Qwen2.5-7B-Instruct | **0.50** |
| Ubuntu-24.04 | CPU i3-12300 | GTCRN | FSMN | SenseVoiceSmall | - | **0.054** |
| Ubuntu-24.04 | CPU i3-12300 | ZipEnhancer | FSMN | SenseVoiceSmall | - | **0.39** |
| Ubuntu-24.04 | CPU i3-12300 | GTCRN | Silero | Whisper-Large-V3 | - | **0.20** |
| Ubuntu-24.04 | CPU i3-12300 | GTCRN | FSMN | Whisper-Large-V3-Turbo | - | **0.148** |

---

## üõ†Ô∏è Troubleshooting

### Common Issues
- **Silero VAD Error**: Simply restart the application on first run
- **libc++ Error** (Linux):
  ```bash
  sudo apt update
  sudo apt install libc++1
  ```
- **Apple Silicon**: Avoid installing `onnxruntime-openvino` as it will cause errors

---

## üó∫Ô∏è Roadmap

- [ ] **[Video Upscaling](https://github.com/sczhou/Upscale-A-Video)** - Enhance resolution
- [ ] **Real-time Player** - Live transcription and translation

---

<div align="center">

**Ready to get started?** üéâ

[Download Models](https://huggingface.co/H5N1AIDS/Transcribe_and_Translate_Subtitles) ‚Ä¢ [View Documentation](https://github.com/your-repo) ‚Ä¢ [Report Issues](https://github.com/your-repo/issues)

</div>

---
# üé¨ ËßÜÈ¢ëÂ≠óÂπïËΩ¨ÂΩïÂíåÁøªËØëÂ∑•ÂÖ∑

<div align="center">

**Âº∫Â§ßÁöÑÈöêÁßÅ‰ºòÂÖàËßÜÈ¢ëÂ≠óÂπïËΩ¨ÂΩïÁøªËØëÂ∑•ÂÖ∑**

[![ÈöêÁßÅ‰ºòÂÖà](https://img.shields.io/badge/ÈöêÁßÅ-100%25%20Êú¨Âú∞-green.svg)](https://github.com/your-repo)
[![ONNX Runtime](https://img.shields.io/badge/Âü∫‰∫é-ONNX%20Runtime-blue.svg)](https://onnxruntime.ai/)
[![Â§öÂπ≥Âè∞](https://img.shields.io/badge/Âπ≥Âè∞-Windows%20%7C%20Linux%20%7C%20macOS-lightgrey.svg)](https://github.com/your-repo)

</div>

---

## üîí ÈöêÁßÅ‰øùÈöú

> **üö® ÊâÄÊúâÂ§ÑÁêÜÂÆåÂÖ®Á¶ªÁ∫øËøêË°å** - Êó†ÈúÄ‰∫íËÅîÁΩëËøûÊé•ÔºåÁ°Æ‰øùÊúÄÂ§ßÈöêÁßÅÂíåÊï∞ÊçÆÂÆâÂÖ®„ÄÇ

---

## üìã ÂÆåÊï¥Êõ¥Êñ∞ÂéÜÂè≤

### üÜï **2025/9/19** - ÈáçÂ§ßÁâàÊú¨ÂèëÂ∏É
- ‚úÖ **Êñ∞Â¢û ASR**: 30+ Âú∞Âå∫ÂæÆË∞É Whisper Ê®°Âûã
- ‚úÖ **Êñ∞Â¢ûÈôçÂô™Âô®**: MossFormer2_SE_48K
- ‚úÖ **Êñ∞Â¢ûÂ§ßËØ≠Ë®ÄÊ®°Âûã**:
  - Qwen3-4B-Instruct-2507-abliterated
  - Qwen3-8B-abliterated-v2
  - Hunyuan-MT-7B-abliterated
  - Seed-X-PRO-7B
- ‚úÖ **ÊÄßËÉΩÊîπËøõ**:
  - ‰∏∫ Whisper Á±ªÂûã ASR Ê®°ÂûãÂ∫îÁî® Beam Search
  - Â∫îÁî® ONNX Runtime IOBinding ÂÆûÁé∞ÊúÄÂ§ßÈÄüÂ∫¶ÊèêÂçáÔºàÊØîÊôÆÈÄö ort_session_C.run() Âø´ 10%+Ôºâ
  - ÊîØÊåÅÂçïÊ¨°Êé®ÁêÜËøêË°å 20 ÁßíÈü≥È¢ëÁâáÊÆµ
  - ÊîπËøõÂ§öÁ∫øÁ®ãÊÄßËÉΩ
- ‚úÖ **Á°¨‰ª∂ÊîØÊåÅÊâ©Â±ï**:
  - AMD-ROCm ÊâßË°åÊèê‰æõÂô®
  - AMD-MIGraphX ÊâßË°åÊèê‰æõÂô®
  - NVIDIA TensorRTX ÊâßË°åÊèê‰æõÂô®
  - *ÔºàÂøÖÈ°ªÂÖàÈÖçÁΩÆÁéØÂ¢ÉÔºåÂê¶ÂàôÊó†Ê≥ïÂ∑•‰ΩúÔºâ*
- ‚úÖ **ÂáÜÁ°ÆÊÄßÊîπËøõ**:
  - SenseVoice
  - Paraformer
  - FireRedASR
  - Dolphin
  - ZipEnhancer
  - MossFormerGAN_SE_16K
  - NVIDIA-NeMo-VAD
- ‚úÖ **ÈÄüÂ∫¶ÊîπËøõ**:
  - MelBandRoformerÔºàÈÄöËøáËΩ¨Êç¢‰∏∫ÂçïÂ£∞ÈÅìÂÆûÁé∞ÈÄüÂ∫¶ÊèêÂçáÔºâ
- ‚ùå **ÁßªÈô§ÁöÑÊ®°Âûã**:
  - FSMN-VAD
  - Qwen3-4B-Official
  - Qwen3-8B-Official
  - Gemma3-4B-it
  - Gemma3-12B-it
  - InternLM3
  - Phi-4-Instruct

### **2025/7/5** - ÈôçÂô™Â¢ûÂº∫
- ‚úÖ **Êñ∞Â¢ûÈôçÂô™Ê®°Âûã**: MossFormerGAN_SE_16K

### **2025/6/11** - VAD Ê®°ÂûãÊâ©Â±ï
- ‚úÖ **Êñ∞Â¢û VAD Ê®°Âûã**:
  - HumAware-VAD
  - NVIDIA-NeMo-VAD
  - TEN-VAD

### **2025/6/3** - ‰∫öÊ¥≤ËØ≠Ë®ÄÊîØÊåÅ
- ‚úÖ **Êñ∞Â¢û Dolphin ASR Ê®°Âûã** ‰ª•ÊîØÊåÅ‰∫öÊ¥≤ËØ≠Ë®Ä

### **2025/5/13** - GPU Âä†ÈÄü
- ‚úÖ **Êñ∞Â¢û Float16/32 ASR Ê®°Âûã** ‰ª•ÊîØÊåÅ CUDA/DirectML GPU ‰ΩøÁî®
- ‚úÖ **GPU ÊÄßËÉΩ**: Ëøô‰∫õÊ®°ÂûãÂèØÂÆûÁé∞ >99% GPU ÁÆóÂ≠êÈÉ®ÁΩ≤

### **2025/5/9** - ‰∏ªË¶ÅÂäüËÉΩÂèëÂ∏É
- ‚úÖ **ÁÅµÊ¥ªÊÄßÊîπËøõ**:
  - Êñ∞Â¢ûÈÄâÈ°πÂèØ‰ª•**‰∏ç‰ΩøÁî®** VADÔºàËØ≠Èü≥Ê¥ªÂä®Ê£ÄÊµãÔºâ
- ‚úÖ **Êñ∞Â¢ûÊ®°Âûã**:
  - **ÈôçÂô™**: MelBandRoformer
  - **ASR**: CrisperWhisper
  - **ASR**: Whisper-Large-v3.5-DistilÔºàËã±ËØ≠ÂæÆË∞ÉÔºâ
  - **ASR**: FireRedASR-AED-LÔºà‰∏≠Êñá+ÊñπË®ÄÊîØÊåÅÔºâ
  - **‰∏â‰∏™Êó•ËØ≠Âä®Êº´ÂæÆË∞É Whisper Ê®°Âûã**
- ‚úÖ **ÊÄßËÉΩ‰ºòÂåñ**:
  - ÁßªÈô§ IPEX-LLM Ê°ÜÊû∂‰ª•ÊèêÈ´òÊï¥‰ΩìÊÄßËÉΩ
  - ÂèñÊ∂à LLM ÈáèÂåñÈÄâÈ°πÔºåÊ†áÂáÜÂåñ‰∏∫ **Q4F32** Ê†ºÂºè
  - **Whisper** Á≥ªÂàóÊé®ÁêÜÈÄüÂ∫¶ÊèêÂçáË∂ÖËøá 10%
- ‚úÖ **ÂáÜÁ°ÆÊÄßÊîπËøõ**:
  - ÊîπËøõ **FSMN-VAD** ÂáÜÁ°ÆÊÄß
  - ÊîπËøõ **Paraformer** ËØÜÂà´ÂáÜÁ°ÆÊÄß
  - ÊîπËøõ **SenseVoice** ËØÜÂà´ÂáÜÁ°ÆÊÄß
- ‚úÖ **ÊîØÊåÅ ONNX Runtime 100% GPU ÁÆóÂ≠êÈÉ®ÁΩ≤ÁöÑ LLM**:
  - Qwen3-4B/8B
  - InternLM3-8B
  - Phi-4-mini-Instruct
  - Gemma3-4B/12B-it
- ‚úÖ **Á°¨‰ª∂ÊîØÊåÅÊâ©Â±ï**:
  - **Intel OpenVINO**
  - **NVIDIA CUDA GPU**
  - **Windows DirectML GPU**ÔºàÊîØÊåÅÈõÜÊàêÂíåÁã¨Á´ã GPUÔºâ

---

## üöÄ Âø´ÈÄüÂºÄÂßã

### ÂâçÁΩÆË¶ÅÊ±Ç
```bash
# ÂÆâË£Ö FFmpeg
conda install ffmpeg

# ÂÆâË£Ö Python ‰æùËµñ
pip install -r requirements.txt
```

### ËÆæÁΩÆÊ≠•È™§
1. **‰∏ãËΩΩÊ®°Âûã**: ‰ªé [HuggingFace](https://huggingface.co/H5N1AIDS/Transcribe_and_Translate_Subtitles) Ëé∑ÂèñÊâÄÈúÄÊ®°Âûã
2. **‰∏ãËΩΩËÑöÊú¨**: Â∞Ü `run.py` ÊîæÂÖ•ÊÇ®ÁöÑ `Transcribe_and_Translate_Subtitles` Êñá‰ª∂Â§π
3. **Ê∑ªÂä†Â™í‰Ωì**: Â∞ÜÊÇ®ÁöÑËßÜÈ¢ëÊîæÂÖ• `Transcribe_and_Translate_Subtitles/Media/`
4. **ËøêË°å**: ÊâßË°å `python run.py` Âπ∂ÊâìÂºÄÁΩëÈ°µÁïåÈù¢

### ÁªìÊûúËæìÂá∫
Âú®‰ª•‰∏ã‰ΩçÁΩÆÊâæÂà∞ÊÇ®Â§ÑÁêÜÁöÑÂ≠óÂπï:
```
Transcribe_and_Translate_Subtitles/Results/Subtitles/
```

---

## ‚ú® ÂäüËÉΩÁâπÊÄß

### üîá ÈôçÂô™Ê®°Âûã
- **[DFSMN](https://modelscope.cn/models/iic/speech_dfsmn_ans_psm_48k_causal)** - È´òË¥®ÈáèÈôçÂô™
- **[GTCRN](https://github.com/Xiaobin-Rong/gtcrn)** - ÂÆûÊó∂Âô™Â£∞ÊäëÂà∂
- **[ZipEnhancer](https://modelscope.cn/models/iic/speech_zipenhancer_ans_multiloss_16k_base)** - È´òÁ∫ßÂ¢ûÂº∫
- **[Mel-Band-Roformer](https://github.com/KimberleyJensen/Mel-Band-Roformer-Vocal-Model)** - ‰∫∫Â£∞ÂàÜÁ¶ª
- **[MossFormerGAN_SE_16K](https://www.modelscope.cn/models/alibabasglab/MossFormerGAN_SE_16K)** - 16kHz Â¢ûÂº∫
- **[MossFormer2_SE_48K](https://www.modelscope.cn/models/alibabasglab/MossFormer2_SE_48K)** - 48kHz Â¢ûÂº∫

### üé§ ËØ≠Èü≥Ê¥ªÂä®Ê£ÄÊµã (VAD)
- **[Faster_Whisper-Silero](https://github.com/SYSTRAN/faster-whisper/blob/master/faster_whisper/vad.py)** - Âø´ÈÄüÂáÜÁ°Æ
- **[Official-Silero-v6](https://github.com/snakers4/silero-vad)** - ÂÆòÊñπÂÆûÁé∞
- **[HumAware](https://huggingface.co/CuriousMonkey7/HumAware-VAD)** - ‰∫∫Á±ªÊÑüÁü•Ê£ÄÊµã
- **[NVIDIA-NeMo-VAD-v2.0](https://huggingface.co/nvidia/Frame_VAD_Multilingual_MarbleNet_v2.0)** - Â§öËØ≠Ë®ÄÊîØÊåÅ
- **[TEN-VAD](https://github.com/TEN-framework/ten-vad)** - ËΩªÈáèÁ∫ßÊ£ÄÊµã
- **[Pyannote-Segmentation-3.0](https://huggingface.co/pyannote/segmentation-3.0)** - È´òÁ∫ßÂàÜÂâ≤
  - *Ê≥®ÊÑèÔºöÊÇ®ÈúÄË¶ÅÊé•Âèó Pyannote ÁöÑ‰ΩøÁî®Êù°Ê¨æÂπ∂‰∏ãËΩΩ Pyannote `pytorch_model.bin` Êñá‰ª∂„ÄÇÂ∞ÜÂÖ∂ÊîæÁΩÆÂú® `VAD/pyannote_segmentation` Êñá‰ª∂Â§π‰∏≠„ÄÇ*

### üó£Ô∏è ËØ≠Èü≥ËØÜÂà´ (ASR)
#### Â§öËØ≠Ë®ÄÊ®°Âûã
- **[SenseVoice-Small](https://modelscope.cn/models/iic/SenseVoiceSmall)** - Á¥ßÂáëÂ§öËØ≠Ë®Ä
- **[Whisper-Large-V3](https://huggingface.co/openai/whisper-large-v3)** - ÊúÄÂÖàËøõÂáÜÁ°ÆÊÄß
- **[Whisper-Large-V3-Turbo](https://huggingface.co/openai/whisper-large-v3-turbo)** - ÈÄüÂ∫¶‰ºòÂåñ
- **[CrisperWhisper](https://github.com/nyrahealth/CrisperWhisper)** - Â¢ûÂº∫Ê∏ÖÊô∞Â∫¶
- **[Dolphin-Small](https://github.com/DataoceanAI/Dolphin)** - ‰∫öÊ¥≤ËØ≠Ë®ÄÊîØÊåÅ

#### ‰∏≠ÊñáÊ®°Âûã
- **[Paraformer-Small-Chinese](https://modelscope.cn/models/iic/speech_paraformer_asr_nat-zh-cn-16k-common-vocab8358-tensorflow1)** - Á¥ßÂáë‰∏≠Êñá
- **[Paraformer-Large-Chinese](https://modelscope.cn/models/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch)** - È´òÁ∫ß‰∏≠Êñá
- **[FireRedASR-AED-L](https://github.com/FireRedTeam/FireRedASR)** - ‰∏≠ÊñáÊñπË®ÄÊîØÊåÅ

#### Ëã±ÊñáÊ®°Âûã
- **[Paraformer-Large-English](https://modelscope.cn/models/iic/speech_paraformer_asr-en-16k-vocab4199-pytorch)** - Ëã±ËØ≠‰∏ìÁî®
- **[Whisper-Large-v3.5-Distil](https://huggingface.co/distil-whisper/distil-large-v3.5)** - Ëí∏È¶èÊïàÁéá

#### Êó•ËØ≠Ê®°Âûã
- **[Whisper-Large-V3-Turbo-Japanese](https://huggingface.co/hhim8826/whisper-large-v3-turbo-ja)** - Êó•ËØ≠‰ºòÂåñ
- **[Whisper-Large-V3-Anime-A](https://huggingface.co/efwkjn/whisper-ja-anime-v0.1)** - Âä®Êº´‰∏ìÁî®
- **[Whisper-Large-V3-Anime-B](https://huggingface.co/litagin/anime-whisper)** - Êõø‰ª£Âä®Êº´Ê®°Âûã

### ü§ñ ÁøªËØëÊ®°Âûã (LLM)
- **[Qwen-3-4B-Instruct-2507](https://huggingface.co/huihui-ai/Huihui-Qwen3-4B-Instruct-2507-abliterated)** - È´òÊïàÊåá‰ª§ÈÅµÂæ™
- **[Qwen-3-8B-Fine_Tuned](https://huggingface.co/huihui-ai/Huihui-Qwen3-8B-abliterated-v2)** - Â¢ûÂº∫ 8B Âèò‰Ωì
- **[Hunyuan-MT-7B](https://www.modelscope.cn/models/Tencent-Hunyuan/Hunyuan-MT-7B)** - Êú∫Âô®ÁøªËØë‰∏ìÂÆ∂
- **[Seed-X-PRO-7B](https://www.modelscope.cn/models/ByteDance-Seed/Seed-X-PPO-7B)** - È´òÁ∫ßÊé®ÁêÜ

---

## üñ•Ô∏è Á°¨‰ª∂ÊîØÊåÅ

<table>
<tr>
<td align="center"><strong>üíª CPU</strong></td>
<td align="center"><strong>üéÆ GPU</strong></td>
<td align="center"><strong>üß† ‰∏ìÁî®Á°¨‰ª∂</strong></td>
</tr>
<tr>
<td>Intel ‚Ä¢ AMD ‚Ä¢ Apple Silicon</td>
<td>NVIDIA CUDA ‚Ä¢ AMD ROCm ‚Ä¢ DirectML</td>
<td>Intel OpenVINO ‚Ä¢ TensorRT ‚Ä¢ MIGraphX</td>
</tr>
</table>

**ÂΩìÂâçÊîØÊåÅÁöÑÂπ≥Âè∞:**
- **Intel-OpenVINO-CPU-GPU-NPU**
- **Windows-AMD-GPU**
- **NVIDIA-GPU**
- **Apple-CPU**
- **AMD-CPU**

---

## üìä ÊÄßËÉΩÂü∫ÂáÜÊµãËØï

*ÊµãËØïÊù°‰ª∂: Ubuntu 24.04, Intel i3-12300, 7602 ÁßíËßÜÈ¢ë*

| Êìç‰ΩúÁ≥ªÁªü | ÂêéÁ´Ø | ÈôçÂô™Âô® | VAD | ASR | LLM | ÂÆûÊó∂Âõ†Â≠ê |
|:--:|:-------:|:--------:|:---:|:---:|:---:|:----------------:|
| Ubuntu-24.04 | CPU i3-12300 | - | Silero | SenseVoiceSmall | - | **0.08** |
| Ubuntu-24.04 | CPU i3-12300 | GTCRN | Silero | SenseVoiceSmall | Qwen2.5-7B-Instruct | **0.50** |
| Ubuntu-24.04 | CPU i3-12300 | GTCRN | FSMN | SenseVoiceSmall | - | **0.054** |
| Ubuntu-24.04 | CPU i3-12300 | ZipEnhancer | FSMN | SenseVoiceSmall | - | **0.39** |
| Ubuntu-24.04 | CPU i3-12300 | GTCRN | Silero | Whisper-Large-V3 | - | **0.20** |
| Ubuntu-24.04 | CPU i3-12300 | GTCRN | FSMN | Whisper-Large-V3-Turbo | - | **0.148** |

---

## üõ†Ô∏è ÊïÖÈöúÊéíÈô§

### Â∏∏ËßÅÈóÆÈ¢ò
- **Silero VAD ÈîôËØØ**: È¶ñÊ¨°ËøêË°åÊó∂ÁÆÄÂçïÈáçÂêØÂ∫îÁî®Á®ãÂ∫èÂç≥ÂèØ
- **libc++ ÈîôËØØ** (Linux):
  ```bash
  sudo apt update
  sudo apt install libc++1
  ```
- **Apple Silicon**: ÈÅøÂÖçÂÆâË£Ö `onnxruntime-openvino`ÔºåÂõ†‰∏∫ÂÆÉ‰ºöÂØºËá¥ÈîôËØØ

---

## üó∫Ô∏è Ë∑ØÁ∫øÂõæ

- [ ] **[ËßÜÈ¢ëÂçáÁ∫ß](https://github.com/sczhou/Upscale-A-Video)** - ÊèêÂçáÂàÜËæ®Áéá
- [ ] **ÂÆûÊó∂Êí≠ÊîæÂô®** - ÂÆûÊó∂ËΩ¨ÂΩïÂíåÁøªËØë

---

<div align="center">

**ÂáÜÂ§áÂºÄÂßã‰∫ÜÂêóÔºü** üéâ

[‰∏ãËΩΩÊ®°Âûã](https://huggingface.co/H5N1AIDS/Transcribe_and_Translate_Subtitles) ‚Ä¢ [Êü•ÁúãÊñáÊ°£](https://github.com/your-repo) ‚Ä¢ [Êä•ÂëäÈóÆÈ¢ò](https://github.com/your-repo/issues)

</div>
